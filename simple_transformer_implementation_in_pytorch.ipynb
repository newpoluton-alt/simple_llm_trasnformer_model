{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Simple Transformer Implementation in PyTorch\n",
    "\n",
    "Architecture of the transformer model:\n",
    "* Input Embedding with Positional Encoding\n",
    "* Multi-Head Attention\n",
    "* Multi-Layer Perceptron (MLP)\n",
    "* Transformer Block\n",
    "* Output Layer\n",
    "\n"
   ],
   "id": "8a77807f92f26ee"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Import required libraries\n",
   "id": "20e80ab5878b48b8"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-09T19:40:52.723279Z",
     "start_time": "2026-02-09T19:40:48.354340Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import urllib.request\n",
    "import os\n",
    "from dataclasses import dataclass\n",
    "from typing import Any, Tuple, List\n",
    "\n",
    "from tokenizers import Tokenizer\n",
    "from tokenizers.models import BPE\n",
    "from tokenizers.trainers import BpeTrainer\n",
    "from tokenizers.pre_tokenizers import Whitespace\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.optim import Adam\n",
    "import math\n",
    "from scipy.ndimage import uniform_filter1d\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "import numpy as np"
   ],
   "id": "fbc121e30a2defb3",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-09T19:40:53.006132Z",
     "start_time": "2026-02-09T19:40:52.729645Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(\"PyTorch version:\", torch.__version__)\n",
    "print(\"CUDA available:\", torch.cuda.is_available())"
   ],
   "id": "95018eb7b1c85cd",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch version: 2.9.0+cu126\n",
      "CUDA available: True\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Dataset Preparation",
   "id": "a4d7426c1fad5dd2"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Download the tiny Shakespeare dataset",
   "id": "d7971e470bd0d2c1"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-09T19:40:53.404154Z",
     "start_time": "2026-02-09T19:40:53.016639Z"
    }
   },
   "cell_type": "code",
   "source": [
    "URL = \"https://raw.githubusercontent.com/karpathy/char-rnn/master/data/tinyshakespeare/input.txt\"\n",
    "FILE_NAME = \"input.txt\"\n",
    "DATA_DIR = \"data\"\n",
    "os.makedirs(DATA_DIR, exist_ok=True)\n",
    "\n",
    "FULL_PATH = os.path.join(DATA_DIR, FILE_NAME)\n",
    "\n",
    "# Download the dataset if it doesn't exist\n",
    "if not os.path.exists(FULL_PATH):\n",
    "    urllib.request.urlretrieve(URL, FULL_PATH)\n",
    "\n",
    "print(\"Dataset downloaded to:\", FULL_PATH)\n",
    "\n",
    "with open(FULL_PATH, 'r', encoding='utf-8') as f:\n",
    "    text = f.read()\n",
    "    print(\"Dataset length (characters):\", len(text))"
   ],
   "id": "3dc0d33e9c3708a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset downloaded to: data/input.txt\n",
      "Dataset length (characters): 1115394\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Tokenization",
   "id": "ca5b087856f28714"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-09T19:40:53.619768Z",
     "start_time": "2026-02-09T19:40:53.412444Z"
    }
   },
   "cell_type": "code",
   "source": [
    "VOCAB_SIZE = int(math.sqrt(len(text)))\n",
    "TOKENIZER_SAVE_PATH = os.path.join(DATA_DIR, \"bpe_tokenizer.json\")\n",
    "\n",
    "def train_bpe_tokenizer(text: str, vocab_size:int, save_path: str) -> Tokenizer:\n",
    "    tokenizer = Tokenizer(BPE(unk_token=\"[UNK]\"))\n",
    "    tokenizer.pre_tokenizer = Whitespace()\n",
    "\n",
    "    trainer = BpeTrainer(\n",
    "        vocab_size=vocab_size,\n",
    "        special_tokens = [\"[UNK]\", \"[PAD]\", \"[BOS]\", \"[EOS]\"],\n",
    "        show_progress=True\n",
    "    )\n",
    "\n",
    "    tokenizer.train_from_iterator([text], trainer=trainer)\n",
    "    tokenizer.save(save_path)\n",
    "\n",
    "    print(\"Tokenizer trained and saved to:\", save_path)\n",
    "    return tokenizer"
   ],
   "id": "70544c5f47030953",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-09T19:40:54.353992Z",
     "start_time": "2026-02-09T19:40:53.621226Z"
    }
   },
   "cell_type": "code",
   "source": [
    "tokenizer = train_bpe_tokenizer(text, VOCAB_SIZE, TOKENIZER_SAVE_PATH)\n",
    "\n"
   ],
   "id": "122386bb5297b6ae",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenizer trained and saved to: data/bpe_tokenizer.json\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Create PyTorch Dataset and DataLoader",
   "id": "26899d2c89b85ee8"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-09T19:40:54.560480Z",
     "start_time": "2026-02-09T19:40:54.355282Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, text: str, tokenizer: Tokenizer, seq_length: int = 128, train: bool = True, train_split: float = 0.8):\n",
    "        self.text = text\n",
    "        self.tokenizer = tokenizer\n",
    "        self.seq_length = seq_length\n",
    "        self.train = train\n",
    "        self.train_split = train_split\n",
    "\n",
    "        # Encode the entire text\n",
    "        encoded_text = self.tokenizer.encode(self.text)\n",
    "        self.tokens = torch.tensor(encoded_text.ids, dtype=torch.long)\n",
    "\n",
    "        # Split into train and validation sets\n",
    "        split_idx = int(len(self.tokens) * self.train_split)\n",
    "        if self.train:\n",
    "            self.tokens = self.tokens[:split_idx]\n",
    "        else:\n",
    "            self.tokens = self.tokens[split_idx:]\n",
    "\n",
    "        print(\"Dataset initialized. Total tokens:\", len(self.tokens))\n",
    "\n",
    "    def __len__(self):\n",
    "        return max(0, len(self.tokens) - self.seq_length)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.tokens[idx:idx+self.seq_length], self.tokens[idx+1:idx+self.seq_length+1]\n"
   ],
   "id": "e25734be5ea7fdf1",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-09T19:40:56.416873Z",
     "start_time": "2026-02-09T19:40:54.561541Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Create train and validation datasets\n",
    "SEQ_LENGTH = 128\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "train_dataset = CustomDataset(text, tokenizer, seq_length=SEQ_LENGTH, train=True)\n",
    "val_dataset = CustomDataset(text, tokenizer, seq_length=SEQ_LENGTH, train=False)\n",
    "\n",
    "# Create DataLoaders\n",
    "# For training, we shuffle the data to ensure the model sees different sequences each epoch\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "# Note: For validation, we typically don't shuffle the data because we want to evaluate on the same sequence of data each epoch\n",
    "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False)"
   ],
   "id": "17dc599f44ad4f9b",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset initialized. Total tokens: 303268\n",
      "Dataset initialized. Total tokens: 75817\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Transformer Model Implementation",
   "id": "abbccca56a57689b"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Transformer Input Embedding with Sinusoidal Positional Encoding",
   "id": "63e618dd7e8261e7"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-09T19:40:56.648195Z",
     "start_time": "2026-02-09T19:40:56.433245Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class TransformerInputEmbedding(nn.Module):\n",
    "    def __init__(self, vocab_size: int, embed_dim: int, max_seq_length: int, *args: Any, **kwargs: Any):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.token_embedding = nn.Embedding(vocab_size, embed_dim)\n",
    "        pe = self._create_positional_encoding(max_seq_length, embed_dim)\n",
    "        self.register_buffer('positional_encoding', pe)\n",
    "\n",
    "\n",
    "    def _create_positional_encoding(self, max_seq_length: int, embed_dim: int) -> torch.Tensor:\n",
    "        pe = torch.zeros(max_seq_length, embed_dim) # Shape (max_seq_length, embed_dim)\n",
    "        position = torch.arange(0, max_seq_length).unsqueeze(1).float() # Shape (max_seq_length, 1)\n",
    "        div_term = torch.exp(torch.arange(0, embed_dim, 2).float() * (-math.log(10000.0) / embed_dim)) # Shape (embed_dim/2,)\n",
    "        # For even elements where we get shape (max_seq_length, ceil(embed_dim/2)) after multiplication\n",
    "        pe[:,0::2] = torch.sin(position * div_term)\n",
    "        # For odd elements where we get shape (max_seq_length, ceil(embed_dim/2)) after multiplication\n",
    "        pe[:,1::2] = torch.cos(position * div_term[:pe[:,1::2].shape[1]])\n",
    "\n",
    "        return pe.unsqueeze(0)  # Shape: (1, max_seq_length, embed_dim)\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        # x: (batch, seq_len), dtype long\n",
    "        seq_length = x.size(1)\n",
    "        if seq_length > self.positional_encoding.size(1):\n",
    "            raise ValueError(f\"seq_length={seq_length} exceeds max_seq_length={self.positional_encoding.size(1)}\")\n",
    "\n",
    "        token_embeds = self.token_embedding(x)  # (batch, seq_len, embed_dim)\n",
    "        pos_embeds = self.positional_encoding[:, :seq_length, :]  # (1, seq_len, embed_dim)\n",
    "        return token_embeds + pos_embeds"
   ],
   "id": "8c40f42d19d59bbd",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Multi-Head Attention",
   "id": "af86cbcba29fc2a9"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-09T19:40:56.879688Z",
     "start_time": "2026-02-09T19:40:56.649900Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(self, embed_dim: int, num_heads: int, dropout: float = 0.1, *args: Any, **kwargs: Any):\n",
    "        super().__init__(*args, **kwargs)\n",
    "\n",
    "        # embed_dim must be divisible by num_heads\n",
    "        assert embed_dim % num_heads == 0, \"embed_dim must be divisible by num_heads\"\n",
    "\n",
    "        self.embed_dim = embed_dim\n",
    "        self.num_heads = num_heads\n",
    "        self.head_dim = embed_dim // num_heads\n",
    "\n",
    "        self.q_proj = nn.Linear(embed_dim, embed_dim)\n",
    "        self.k_proj = nn.Linear(embed_dim, embed_dim)\n",
    "        self.v_proj = nn.Linear(embed_dim, embed_dim)\n",
    "        self.out_proj = nn.Linear(embed_dim, embed_dim)\n",
    "\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self,\n",
    "                x: torch.Tensor,\n",
    "                attn_mask: torch.Tensor | None = None,\n",
    "                key_padding_mask: torch.Tensor | None = None,\n",
    "                is_causal: bool = False, return_attn =False\n",
    "                ) -> torch.Tensor | tuple[torch.Tensor, torch.Tensor]:\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            x: (batch, seq_len, embed_dim)\n",
    "            attn_mask: optional mask broadcastable to (batch, num_heads, seq_len, seq_len)\n",
    "                - bool mask: True means \"block this attention\"\n",
    "                - or float mask: additive (e.g., 0 for allow, -inf for block)\n",
    "            key_padding_mask: (batch, seq_len) bool, True for PAD positions to ignore\n",
    "            is_causal: if True, prevents attending to future tokens (GPT-style)\n",
    "            return_attn: if True, also returns attention weights (batch, num_heads, seq_len, seq_len)\n",
    "\n",
    "        Returns:\n",
    "            out: (batch, seq_len, embed_dim)\n",
    "            (optional) attn_weights\n",
    "        \"\"\"\n",
    "\n",
    "        batch_size, seq_len, _ = x.size()\n",
    "\n",
    "        # Linear projections to get Q, K, V: (batch, seq_len, embed_dim)\n",
    "        q = self.q_proj(x)\n",
    "        k = self.k_proj(x)\n",
    "        v = self.v_proj(x)\n",
    "\n",
    "        # Reshape for multi-head: (batch, num_heads, seq_len, head_dim)\n",
    "        q = q.view(batch_size, seq_len, self.num_heads, self.head_dim).transpose(1, 2)\n",
    "        k = k.view(batch_size, seq_len, self.num_heads, self.head_dim).transpose(1, 2)\n",
    "        v = v.view(batch_size, seq_len, self.num_heads, self.head_dim).transpose(1, 2)\n",
    "\n",
    "        # Scaled dot-product attention scores: (batch, num_heads, seq_len, seq_len)\n",
    "        scale = 1.0 / math.sqrt(self.head_dim)\n",
    "        attn_scores = (q @ k.transpose(-2, -1)) * scale\n",
    "\n",
    "        # value used as a negative infinity for masking\n",
    "        neg_inf = torch.finfo(attn_scores.dtype).min\n",
    "\n",
    "        # Causal mask (prevent attending to future tokens)\n",
    "        if is_causal:\n",
    "            causal_mask = torch.triu(torch.ones(seq_len, seq_len, device=x.device, dtype=torch.bool), diagonal=1) # (seq_len, seq_len)\n",
    "            attn_scores = attn_scores.masked_fill(causal_mask, neg_inf)\n",
    "\n",
    "        # Attention mask (e.g., for padding)\n",
    "        if attn_mask is not None:\n",
    "            if attn_mask.dtype == torch.bool:\n",
    "                attn_scores = attn_scores.masked_fill(attn_mask, neg_inf)\n",
    "            else:\n",
    "                attn_scores = attn_scores + attn_mask\n",
    "\n",
    "        # Key padding mask (mask out PAD tokens)\n",
    "        if key_padding_mask is not None:\n",
    "            # key padding mask: (batch, seq_len) -> (batch, 1, 1, seq_len) for broadcasting\n",
    "            key_padding_mask = key_padding_mask[:, None, None, :]\n",
    "            attn_scores = attn_scores.masked_fill(key_padding_mask, neg_inf)\n",
    "\n",
    "        # Attention weights\n",
    "        attn_weights = F.softmax(attn_scores, dim=-1)  # (batch, num_heads, seq_len, seq_len)\n",
    "        attn_weights = self.dropout(attn_weights)\n",
    "\n",
    "        # Weighted sum of values\n",
    "        context = attn_weights @ v  # (batch, num_heads, seq_len, head_dim)\n",
    "        context = context.transpose(1, 2).contiguous().view(batch_size, seq_len, self.embed_dim)  # (batch, seq_len, embed_dim\n",
    "\n",
    "        # Final linear projection\n",
    "        out = self.out_proj(context)  # (batch, seq_len, embed_dim)\n",
    "        out = self.dropout(out)\n",
    "\n",
    "        if return_attn:\n",
    "            return out, attn_weights\n",
    "\n",
    "        return out\n",
    "\n"
   ],
   "id": "2bde0a27218cb290",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Multi-Layer Perceptron (MLP)",
   "id": "1abe7719b918a30b"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-09T19:40:57.081079Z",
     "start_time": "2026-02-09T19:40:56.880864Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self, embed_dim: int, hidden_dim: int, dropout: float = 0.1, activation: str = \"gelu\",*args: Any, **kwargs: Any):\n",
    "        super().__init__(*args, **kwargs)\n",
    "\n",
    "        act = activation.lower()\n",
    "\n",
    "        switcher = {\n",
    "            \"gelu\": nn.GELU(),\n",
    "            \"relu\": nn.ReLU(),\n",
    "            \"silu\": nn.SiLU(),\n",
    "            \"tanh\": nn.Tanh(),\n",
    "            \"leakyrelu\": nn.LeakyReLU(),\n",
    "        }\n",
    "\n",
    "        if act not in switcher:\n",
    "            raise ValueError(f\"Unsupported activation: {activation}\")\n",
    "\n",
    "        self.fc1 = nn.Linear(embed_dim, hidden_dim)\n",
    "        self.fc2 = nn.Linear(hidden_dim, embed_dim)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.activation = switcher[act]\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        # x: (batch, seq_len, embed_dim)\n",
    "        x = self.fc1(x)\n",
    "        x = self.activation(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc2(x) # (batch, seq_len, embed_dim)\n",
    "        x = self.dropout(x)\n",
    "\n",
    "        return x"
   ],
   "id": "116c4cb5ed3d996c",
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Transformer block implementation",
   "id": "283c662b0407dade"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Global configuration for the transformer model",
   "id": "43b7b9a53c67a2d7"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-09T19:40:57.288670Z",
     "start_time": "2026-02-09T19:40:57.082533Z"
    }
   },
   "cell_type": "code",
   "source": [
    "@dataclass\n",
    "class ModelConfig:\n",
    "    vocab_size: int = VOCAB_SIZE\n",
    "    max_seq_length: int = SEQ_LENGTH\n",
    "    embed_dim: int = 256\n",
    "    num_heads: int = 8\n",
    "    num_layers: int = 6\n",
    "    dropout: float = 0.1\n",
    "    activation: str = \"gelu\"\n",
    "\n",
    "    # MLP hidden dimension is typically 4x the embed_dim in transformer architectures\n",
    "    mlp_hidden_dim: int = 1024\n",
    "\n",
    "    # Special token IDs (these should match the tokenizer's special tokens)\n",
    "    pad_token_id: int = 1\n",
    "    bos_token_id: int = 2\n",
    "    eos_token_id: int = 3\n",
    "\n"
   ],
   "id": "1c5b6b747599c5e4",
   "outputs": [],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-09T19:40:57.504774Z",
     "start_time": "2026-02-09T19:40:57.295877Z"
    }
   },
   "cell_type": "code",
   "source": "CFG = ModelConfig()",
   "id": "ca0ec5ed34e652df",
   "outputs": [],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-09T19:40:57.729225Z",
     "start_time": "2026-02-09T19:40:57.507089Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class TransformerBlock(nn.Module):\n",
    "    def __init__(self, embed_dim: int, num_heads: int, mlp_hidden_dim: int, dropout: float, activation: str, *args: Any, **kwargs: Any):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.attention = MultiHeadAttention(\n",
    "            embed_dim=embed_dim,\n",
    "            num_heads=num_heads,\n",
    "            dropout=dropout\n",
    "        )\n",
    "        self.norm1 = nn.LayerNorm(embed_dim)\n",
    "        self.mlp = MLP(\n",
    "            embed_dim = embed_dim,\n",
    "            hidden_dim = mlp_hidden_dim,\n",
    "            dropout = dropout,\n",
    "            activation = activation\n",
    "        )\n",
    "        self.norm2 = nn.LayerNorm(embed_dim)\n",
    "\n",
    "    def forward(self, x: torch.Tensor, attn_mask: torch.Tensor | None = None, key_padding_mask: torch.Tensor | None = None, is_causal: bool = True) -> torch.Tensor:\n",
    "        # x: (batch, seq_len, embed_dim)\n",
    "        # Residual connection and layer normalization\n",
    "        x = x + self.attention(self.norm1(x), attn_mask=attn_mask, key_padding_mask=key_padding_mask, is_causal=is_causal)\n",
    "\n",
    "        # Residual connection and layer normalization\n",
    "        x = x +  self.mlp(self.norm2(x))\n",
    "\n",
    "\n",
    "        return x"
   ],
   "id": "301d6a1f2cdbf671",
   "outputs": [],
   "execution_count": 13
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Output layer and Transformer LM assembly",
   "id": "f4204d00502aa9af"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-09T20:07:51.628481Z",
     "start_time": "2026-02-09T20:07:51.384102Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class TransformerLM(nn.Module):\n",
    "    def __init__(self, cfg: ModelConfig, *args: Any, **kwargs: Any):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.cfg = cfg\n",
    "        self.input_embedding = TransformerInputEmbedding(\n",
    "            vocab_size=cfg.vocab_size,\n",
    "            embed_dim=cfg.embed_dim,\n",
    "            max_seq_length=cfg.max_seq_length,\n",
    "        )\n",
    "        self.transformer_blocks = nn.ModuleList([\n",
    "            TransformerBlock(\n",
    "                embed_dim=cfg.embed_dim,\n",
    "                num_heads=cfg.num_heads,\n",
    "                mlp_hidden_dim=cfg.mlp_hidden_dim,\n",
    "                dropout=cfg.dropout,\n",
    "                activation=cfg.activation\n",
    "            ) for _ in range(cfg.num_layers)\n",
    "        ])\n",
    "        self.output_layer = nn.Linear(cfg.embed_dim, cfg.vocab_size)\n",
    "\n",
    "        self.ln_f = nn.LayerNorm(cfg.embed_dim)\n",
    "        self.lm_head = nn.Linear(cfg.embed_dim, cfg.vocab_size, bias=False)\n",
    "\n",
    "        # Tie weights between input embedding and output layer\n",
    "        self.output_layer.weight = self.input_embedding.token_embedding.weight\n",
    "\n",
    "    def forward(self,\n",
    "                x: torch.Tensor,\n",
    "                is_causal: bool = True,\n",
    "                targets: torch.Tensor | None = None,\n",
    "                casual_mask: torch.Tensor | None = None,\n",
    "                key_padding_mask: torch.Tensor | None = None) -> tuple[torch.Tensor, torch.Tensor | None]:\n",
    "        # x: (batch, seq_len)\n",
    "        # targets: (batch, seq_len) or None\n",
    "\n",
    "        # if user didn't provide a padding mask, create one from pad_token_id\n",
    "        if key_padding_mask is None and self.cfg.pad_token_id is not None:\n",
    "            key_padding_mask = (x == self.cfg.pad_token_id)\n",
    "\n",
    "        x = self.input_embedding(x)  # (batch, seq_len, embed_dim)\n",
    "\n",
    "        for block in self.transformer_blocks:\n",
    "            x = block(x, attn_mask=casual_mask, key_padding_mask=key_padding_mask, is_causal=is_causal)\n",
    "\n",
    "        x = self.ln_f(x)  # (batch, seq_len, embed_dim)\n",
    "        logits = self.lm_head(x)  # (batch, seq_len, vocab_size\n",
    "\n",
    "        loss = None\n",
    "        if targets is not None:\n",
    "            # Flatten the logits and targets for cross-entropy loss\n",
    "            B, T, V = logits.size()\n",
    "            logits_2d = logits.view(B * T, V)\n",
    "            targets_1d = targets.view(B * T)\n",
    "\n",
    "            # Ignore PAD in loss calculation\n",
    "            loss = F.cross_entropy(logits_2d, targets_1d, ignore_index=self.cfg.pad_token_id)\n",
    "\n",
    "        return logits, loss"
   ],
   "id": "4623f0c95c885ead",
   "outputs": [],
   "execution_count": 20
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Train and evaluate the model\n",
    "\n",
    "#### Training loop with checkpointing and early stopping"
   ],
   "id": "e97425781242f9c3"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-09T19:40:58.232866Z",
     "start_time": "2026-02-09T19:40:57.966150Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from pathlib import Path\n",
    "from typing import Optional\n",
    "\n",
    "\n",
    "def save_checkpoint(\n",
    "    checkpoint_path: str,\n",
    "    epoch: int,\n",
    "    model: nn.Module,\n",
    "    optimizer: torch.optim.Optimizer,\n",
    "    val_loss: float,\n",
    "):\n",
    "    checkpoint = {\n",
    "        \"epoch\": epoch,\n",
    "        \"model_state_dict\": model.state_dict(),\n",
    "        \"optimizer_state_dict\": optimizer.state_dict(),\n",
    "        \"val_loss\": float(val_loss),\n",
    "    }\n",
    "    torch.save(checkpoint, checkpoint_path)\n",
    "\n",
    "\n",
    "def load_checkpoint(model: nn.Module, checkpoint_path: str, device: str = \"cpu\") -> nn.Module:\n",
    "    checkpoint = torch.load(checkpoint_path, map_location=device)\n",
    "    model.load_state_dict(checkpoint[\"model_state_dict\"])\n",
    "    print(\n",
    "        f\"Loaded checkpoint from epoch {checkpoint['epoch']} \"\n",
    "        f\"with val_loss={checkpoint['val_loss']:.4f}\"\n",
    "    )\n",
    "    return model\n",
    "\n",
    "\n",
    "def _unpack_batch(batch: Any) -> Tuple[torch.Tensor, torch.Tensor, Optional[torch.Tensor]]:\n",
    "\n",
    "    key_padding_mask = None\n",
    "\n",
    "    if isinstance(batch, (list, tuple)):\n",
    "        if len(batch) == 2:\n",
    "            x, y = batch\n",
    "        elif len(batch) == 3:\n",
    "            x, y, key_padding_mask = batch\n",
    "        else:\n",
    "            raise ValueError(\"Batch tuple/list must be (x,y) or (x,y,mask).\")\n",
    "        return x, y, key_padding_mask\n",
    "\n",
    "    if isinstance(batch, dict):\n",
    "        # common naming variations\n",
    "        x = batch.get(\"input_ids\", batch.get(\"x\"))\n",
    "        y = batch.get(\"labels\", batch.get(\"y\"))\n",
    "        key_padding_mask = batch.get(\"key_padding_mask\", None)\n",
    "\n",
    "        if x is None or y is None:\n",
    "            raise ValueError(\"Batch dict must contain input_ids/x and labels/y.\")\n",
    "        return x, y, key_padding_mask\n",
    "\n",
    "    raise ValueError(\"Unsupported batch format.\")\n",
    "\n",
    "\n",
    "def train_model(\n",
    "    model: nn.Module,\n",
    "    train_loader: DataLoader,\n",
    "    val_loader: DataLoader,\n",
    "    num_epochs: int = 10,\n",
    "    learning_rate: float = 1e-4,\n",
    "    checkpoint_dir: str = \"checkpoints\",\n",
    "    patience: int = 3,\n",
    "    device: str = \"cuda\" if torch.cuda.is_available() else \"cpu\",\n",
    "    grad_clip: Optional[float] = 1.0,\n",
    ") -> Tuple[nn.Module, List[float], List[float]]:\n",
    "\n",
    "    os.makedirs(checkpoint_dir, exist_ok=True)\n",
    "    checkpoint_dir = str(Path(checkpoint_dir))\n",
    "\n",
    "    model = model.to(device)\n",
    "    optimizer = Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "    best_val_loss = float(\"inf\")\n",
    "    bad_epochs = 0\n",
    "\n",
    "    train_losses: List[float] = []\n",
    "    val_losses: List[float] = []\n",
    "\n",
    "    best_path = os.path.join(checkpoint_dir, \"best_model.pt\")\n",
    "    last_path = os.path.join(checkpoint_dir, \"last_model.pt\")\n",
    "\n",
    "    for epoch in range(1, num_epochs + 1):\n",
    "        # Train the model for one epoch\n",
    "        model.train()\n",
    "        running_train_loss = 0.0\n",
    "        n_train_batches = 0\n",
    "\n",
    "        for batch in train_loader:\n",
    "            x, y, key_padding_mask = _unpack_batch(batch)\n",
    "\n",
    "            x = x.to(device)\n",
    "            y = y.to(device)\n",
    "            if key_padding_mask is not None:\n",
    "                key_padding_mask = key_padding_mask.to(device)\n",
    "\n",
    "            optimizer.zero_grad(set_to_none=True)\n",
    "\n",
    "            _, loss = model(x, targets=y, key_padding_mask=key_padding_mask)\n",
    "            if loss is None:\n",
    "                raise RuntimeError(\"Model returned loss=None. Make sure you pass targets correctly.\")\n",
    "\n",
    "            loss.backward()\n",
    "\n",
    "            if grad_clip is not None:\n",
    "                torch.nn.utils.clip_grad_norm_(model.parameters(), grad_clip)\n",
    "\n",
    "            optimizer.step()\n",
    "\n",
    "            running_train_loss += loss.item()\n",
    "            n_train_batches += 1\n",
    "\n",
    "        avg_train_loss = running_train_loss / max(1, n_train_batches)\n",
    "        train_losses.append(avg_train_loss)\n",
    "\n",
    "        # Validate the model\n",
    "        model.eval()\n",
    "        running_val_loss = 0.0\n",
    "        n_val_batches = 0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for batch in val_loader:\n",
    "                x, y, key_padding_mask = _unpack_batch(batch)\n",
    "\n",
    "                x = x.to(device)\n",
    "                y = y.to(device)\n",
    "                if key_padding_mask is not None:\n",
    "                    key_padding_mask = key_padding_mask.to(device)\n",
    "\n",
    "                _, loss = model(x, targets=y, key_padding_mask=key_padding_mask)\n",
    "                if loss is None:\n",
    "                    raise RuntimeError(\"Model returned loss=None during validation.\")\n",
    "\n",
    "                running_val_loss += loss.item()\n",
    "                n_val_batches += 1\n",
    "\n",
    "        avg_val_loss = running_val_loss / max(1, n_val_batches)\n",
    "        val_losses.append(avg_val_loss)\n",
    "\n",
    "        # Save \"last\" checkpoint\n",
    "        save_checkpoint(\n",
    "            checkpoint_path=last_path,\n",
    "            epoch=epoch,\n",
    "            model=model,\n",
    "            optimizer=optimizer,\n",
    "            val_loss=avg_val_loss,\n",
    "        )\n",
    "\n",
    "        # Check for improvement\n",
    "        improved = avg_val_loss < best_val_loss\n",
    "        if improved:\n",
    "            best_val_loss = avg_val_loss\n",
    "            bad_epochs = 0\n",
    "            save_checkpoint(\n",
    "                checkpoint_path=best_path,\n",
    "                epoch=epoch,\n",
    "                model=model,\n",
    "                optimizer=optimizer,\n",
    "                val_loss=avg_val_loss,\n",
    "            )\n",
    "        else:\n",
    "            bad_epochs += 1\n",
    "\n",
    "        print(\n",
    "            f\"Epoch {epoch:03d}/{num_epochs} | \"\n",
    "            f\"train_loss={avg_train_loss:.4f} | val_loss={avg_val_loss:.4f} | \"\n",
    "            f\"{'BEST' if improved else f'patience {bad_epochs}/{patience}'}\"\n",
    "        )\n",
    "\n",
    "        # Early stopping\n",
    "        if bad_epochs >= patience:\n",
    "            print(f\"Early stopping: no val improvement for {patience} epochs.\")\n",
    "            break\n",
    "\n",
    "    # Load best weights back into the model before returning\n",
    "    model = load_checkpoint(model, best_path, device=device)\n",
    "    return model, train_losses, val_losses"
   ],
   "id": "2adbfea72513faa9",
   "outputs": [],
   "execution_count": 15
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Train the model",
   "id": "b906feb93b876d0"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-09T20:03:43.874575Z",
     "start_time": "2026-02-09T19:40:58.235530Z"
    }
   },
   "cell_type": "code",
   "source": [
    "CHECKPOINT_DIR = \"checkpoints\"\n",
    "BEST_MODEL_PATH = os.path.join(CHECKPOINT_DIR, \"best_model.pt\")\n",
    "\n",
    "if os.path.exists(BEST_MODEL_PATH):\n",
    "    print(f\"Found existing checkpoint at {BEST_MODEL_PATH}. Loading model from checkpoint...\")\n",
    "    model = load_checkpoint(TransformerLM(CFG), BEST_MODEL_PATH, device=\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "else:\n",
    "    model = TransformerLM(CFG)\n",
    "model, train_losses, val_losses = train_model(\n",
    "    model=model,\n",
    "    train_loader=train_loader,\n",
    "    val_loader=val_loader,\n",
    "    num_epochs=2,\n",
    "    learning_rate=3e-4,\n",
    "    checkpoint_dir=CHECKPOINT_DIR,\n",
    "    patience=5,\n",
    "    device=\"cuda\" if torch.cuda.is_available() else \"cpu\",\n",
    ")"
   ],
   "id": "9110ec6bd079ee63",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 001/2 | train_loss=2.1061 | val_loss=7.6616 | BEST\n",
      "Epoch 002/2 | train_loss=0.6996 | val_loss=9.0745 | patience 1/5\n",
      "Loaded checkpoint from epoch 1 with val_loss=7.6616\n"
     ]
    }
   ],
   "execution_count": 16
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Plot training and validation loss curves",
   "id": "e1ed09214e5f3d55"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-09T20:03:44.174625Z",
     "start_time": "2026-02-09T20:03:43.899800Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def plot_losses_detailed(train_losses: List[float], val_losses: List[float],\n",
    "                        smoothing_window: int = 5, save_path: str = None):\n",
    "    \"\"\"\n",
    "    Plot losses with optional smoothing for clearer trends.\n",
    "\n",
    "    Args:\n",
    "        train_losses: Training losses per epoch\n",
    "        val_losses: Validation losses per epoch\n",
    "        smoothing_window: Window size for moving average smoothing\n",
    "        save_path: Path to save the figure\n",
    "    \"\"\"\n",
    "    epochs = range(1, len(train_losses) + 1)\n",
    "\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 5))\n",
    "\n",
    "    # Raw losses\n",
    "    ax1.plot(epochs, train_losses, 'b-', alpha=0.6, label='Train Loss')\n",
    "    ax1.plot(epochs, val_losses, 'r-', alpha=0.6, label='Val Loss')\n",
    "    ax1.set_xlabel('Epoch')\n",
    "    ax1.set_ylabel('Loss')\n",
    "    ax1.set_title('Raw Losses')\n",
    "    ax1.legend()\n",
    "    ax1.grid(True, alpha=0.3)\n",
    "\n",
    "    # Smoothed losses\n",
    "    if len(train_losses) > smoothing_window:\n",
    "        train_smooth = uniform_filter1d(train_losses, size=smoothing_window)\n",
    "        val_smooth = uniform_filter1d(val_losses, size=smoothing_window)\n",
    "\n",
    "        ax2.plot(epochs, train_smooth, 'b-', linewidth=2, label='Train Loss (smoothed)')\n",
    "        ax2.plot(epochs, val_smooth, 'r-', linewidth=2, label='Val Loss (smoothed)')\n",
    "    else:\n",
    "        ax2.plot(epochs, train_losses, 'b-', linewidth=2, label='Train Loss')\n",
    "        ax2.plot(epochs, val_losses, 'r-', linewidth=2, label='Val Loss')\n",
    "\n",
    "    best_epoch = val_losses.index(min(val_losses)) + 1\n",
    "    ax2.axvline(x=best_epoch, color='g', linestyle='--', alpha=0.5)\n",
    "    ax2.set_xlabel('Epoch')\n",
    "    ax2.set_ylabel('Loss')\n",
    "    ax2.set_title(f'Smoothed Losses (window={smoothing_window})')\n",
    "    ax2.legend()\n",
    "    ax2.grid(True, alpha=0.3)\n",
    "\n",
    "    plt.tight_layout()\n",
    "\n",
    "    if save_path:\n",
    "        plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
    "        print(f\"Plot saved to {save_path}\")\n",
    "\n",
    "    plt.show()\n",
    "    print(f\"\\nBest validation loss: {min(val_losses):.4f} at epoch {best_epoch}\")\n",
    "    print(f\"Final train loss: {train_losses[-1]:.4f}\")\n",
    "    print(f\"Final val loss: {val_losses[-1]:.4f}\")"
   ],
   "id": "1fd13e970e3a4641",
   "outputs": [],
   "execution_count": 17
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Iterative generation function",
   "id": "568ceb422b665a0c"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-09T20:03:44.416248Z",
     "start_time": "2026-02-09T20:03:44.176018Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def sample_next_token(logits: torch.Tensor, temperature: float = 1.0, top_k: int | None = 50) -> int:\n",
    "\n",
    "    if temperature <= 0:\n",
    "        # Greedy\n",
    "        return int(torch.argmax(logits).item())\n",
    "\n",
    "    logits = logits / temperature\n",
    "\n",
    "    if top_k is not None and top_k > 0:\n",
    "        topk_vals, topk_idx = torch.topk(logits, k=min(top_k, logits.size(-1)))\n",
    "        probs = torch.softmax(topk_vals, dim=-1)\n",
    "        next_idx_in_topk = torch.multinomial(probs, num_samples=1).item()\n",
    "\n",
    "        return int(topk_idx[next_idx_in_topk].item())\n",
    "\n",
    "    probs = torch.softmax(logits, dim=-1)\n",
    "    return int(torch.multinomial(probs, num_samples=1).item())\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def generate_text(\n",
    "    model,\n",
    "    tokenizer,\n",
    "    prompt: str,\n",
    "    max_new_tokens: int = 50,\n",
    "    temperature: float = 1.0,\n",
    "    top_k: int | None = 50,\n",
    "    add_bos: bool = False,\n",
    "):\n",
    "    device = next(model.parameters()).device\n",
    "\n",
    "    # Encode prompt -> token ids\n",
    "    ids = tokenizer.encode(prompt).ids\n",
    "\n",
    "    if add_bos and hasattr(model, \"cfg\") and model.cfg.bos_token_id is not None:\n",
    "        ids = [model.cfg.bos_token_id] + ids\n",
    "\n",
    "    # Keep everything in a tensor: (1, T)\n",
    "    x = torch.tensor(ids, dtype=torch.long, device=device).unsqueeze(0)\n",
    "\n",
    "    for _ in range(max_new_tokens):\n",
    "        # If context is longer than model max, crop from the left\n",
    "        if x.size(1) > model.cfg.max_seq_length:\n",
    "            x = x[:, -model.cfg.max_seq_length :]\n",
    "\n",
    "        logits, _ = model(x)              # logits: (1, T, vocab)\n",
    "        last_logits = logits[0, -1, :]    # (vocab_size,)\n",
    "\n",
    "        next_id = sample_next_token(last_logits, temperature=temperature, top_k=top_k)\n",
    "\n",
    "        # Append next token\n",
    "        next_token = torch.tensor([[next_id]], dtype=torch.long, device=device)\n",
    "        x = torch.cat([x, next_token], dim=1)\n",
    "\n",
    "        # Stop on EOS if you use it\n",
    "        if hasattr(model, \"cfg\") and model.cfg.eos_token_id is not None:\n",
    "            if next_id == model.cfg.eos_token_id:\n",
    "                break\n",
    "\n",
    "    # Decode full sequence\n",
    "    out_ids = x[0].tolist()\n",
    "    return tokenizer.decode(out_ids)"
   ],
   "id": "99b505593f2cc463",
   "outputs": [],
   "execution_count": 18
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Generate text with the trained model",
   "id": "7797a7bf49db1e0f"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-09T20:08:54.756959Z",
     "start_time": "2026-02-09T20:08:53.566341Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Load best model later\n",
    "best_model = TransformerLM(CFG)\n",
    "best_model = load_checkpoint(best_model, \"checkpoints/best_model.pt\", device=\"cuda\")\n",
    "\n",
    "prompt = \"To be, or not to be, that is the question:\"\n",
    "out = generate_text(\n",
    "    best_model,\n",
    "    tokenizer,\n",
    "    prompt,\n",
    "    max_new_tokens=40,\n",
    "    temperature=0.9,\n",
    "    top_k=50,\n",
    ")\n",
    "\n",
    "print(out)"
   ],
   "id": "2cf0554b7f8217fd",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded checkpoint from epoch 1 with val_loss=7.6616\n",
      "To be , or not to be , that is the que st ion : The vi ol ate ! LEONTES : H a them out of U nd er a st it , and ' s ink on earth , P o or ha ps , ' We were well know how to give\n"
     ]
    }
   ],
   "execution_count": 21
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-09T20:09:07.776141Z",
     "start_time": "2026-02-09T20:09:06.432537Z"
    }
   },
   "cell_type": "code",
   "source": "plot_losses_detailed(train_losses=train_losses, val_losses=val_losses, smoothing_window=3, save_path=\"loss_curves.png\")",
   "id": "1f47479def10a02c",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plot saved to loss_curves.png\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1500x500 with 2 Axes>"
      ],
      "image/png": "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\n"
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best validation loss: 7.6616 at epoch 1\n",
      "Final train loss: 0.6996\n",
      "Final val loss: 9.0745\n"
     ]
    }
   ],
   "execution_count": 22
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
